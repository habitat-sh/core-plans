# ======================== Elasticsearch Configuration =========================
#
# NOTE: Elasticsearch comes with reasonable defaults for most settings.
#       Before you set out to tweak and tune the configuration, make sure you
#       understand what are you trying to accomplish and the consequences.
#
# The primary way of configuring a node is via this file. This template lists
# the most important settings you may want to configure for a production cluster.
#
# Please see the documentation for further information on configuration options:
# <http://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration.html>
#
# ---------------------------------- Cluster -----------------------------------
#
[cluster]
  #
  # Use a descriptive name for your cluster:
  #
  name = "elasticsearch"

  [cluster.routing.allocation]
    #
    # How many concurrent shard recoveries are allowed to happen on a node.
    # Defaults to 2.
    #
    node_concurrent_recoveries = "2"
    #
    # While the recovery of replicas happens over the network, the recovery of
    # an unassigned primary after node restart uses data from the local disk.
    # These should be fast so more initial primary recoveries can happen in
    # parallel on the same node. Defaults to 4.
    #
    node_initial_primaries_recoveries = "4"
    #
    # Allows to perform a check to prevent allocation of multiple instances of
    # the same shard on a single host, based on host name and host address.
    # Defaults to false, meaning that no check is performed by default. This
    # setting only applies if multiple nodes are started on the same machine.
    #
    same_shard-host = "false"

    allow_rebalance = "indices_all_active"
    cluster_concurrent_rebalance = 2

  [cluster.routing.allocation.awareness]
    #
    # https://www.elastic.co/guide/en/elasticsearch/reference/2.3/allocation-awareness.html
    #
    attributes = ""
  [cluster.routing.allocation.awareness.force.zone]
    # values = ""

  [cluster.routing.allocation.balance]
    shard = "0.45f"
    index = "0.55f"
    threshold = "1.0f"
  [cluster.routing.allocation.disk]
    threshold_enabled = true
    include_relocations = true
  [cluster.routing.allocation.disk.watermark]
    low = "85%"
    high = "90%"
  [cluster.routing.rebalance]
    enable = "all"
  [cluster.info.update]
    interval = "30s"


#
# ------------------------------------ Node ------------------------------------
#
[node]
  # Use a descriptive name for the node:
  #
  name = "${HOSTNAME}"
  #
  # Add custom attributes to the node:
  #
  # node.rack: r1
  #
  rack_id = ""
  zone    = ""
  #
  # Disable starting multiple nodes on a single system:
  #
  max_local_storage_nodes = 1
  #
  # Configure node as master-only, master-eligible, data-only, or client
  # (https://www.elastic.co/guide/en/elasticsearch/reference/2.3/modules-node.html#master-node)
  # Default is master-eligible (master and data are both "true")
  #
  master = "true"
  data   = "true"
  #client = "true"

#
# ----------------------------------- Paths ------------------------------------
#
[path]
  #
  # Path to directory where to store the data (separate multiple locations by comma):
  #
  data =    ""
  #
  # Path to log files:
  #
  logs =    "logs"
  #
  # Path to plugins:
  #
  plugins = "plugins"
  #
  # Path to scripts directory
  #
  scripts = "scripts"

#
# ----------------------------------- Indices ----------------------------------
#
[indices]
  queries-cache-size = "10%"
  [indices.recovery]
    concurrent_streams =            "3"
    concurrent_small_file_streams = "2"
    file_chunk_size =               "512kb"
    translog_ops =                  "1000"
    translog_size =                 "512kb"
    compress =                      "true"
    max_bytes_per_sec  =            "20mb"

  [indices.fielddata]
    #
    # The max size of the field data cache, eg 30% of node heap space, or an absolute
    # value, eg 12GB. Defaults to unbounded.
    #
    cache-size =                   ""

  [indices.breaker]
    #
    # Starting limit for overall parent breaker, defaults to 70% of JVM heap.
    #
    total-limit =                    "70%"
    #
    # Limit for fielddata breaker, defaults to 60% of JVM heap.
    #
    fielddata-limit =                "60%"
    #
    # A constant that all field data estimations are multiplied with to determine a
    # final estimation. Defaults to 1.03
    #
    fielddata-overhead =             "1.03"
    #
    # Limit for request breaker, defaults to 40% of JVM heap.
    #
    request-limit =                  "40%"
    #
    # A constant that all request estimations are multiplied with to determine a
    # final estimation. Defaults to 1.
    #
    request-overhead =               "1"
  [indices.memory]
    index_buffer_size = "10%"
    min_index_buffer_size = "48mb"
    max_index_buffer_size = ""
    min_shard_index_buffer_size = "4mb"
  [indices.ttl]
    interval = "60s"
		bulk_size = 10000

#
# ----------------------------------- Memory -----------------------------------
#
[bootstrap]
  # Lock the memory on startup:
  #
  mlockall = "true"
  #
  # Make sure that the heap size is set to about half the memory available
  # on the system and that the owner of the process is allowed to use this
  # limit.
  #
  # Elasticsearch performs poorly when the system is swapping the memory.
  #

#
# ---------------------------------- Network -----------------------------------
#
[network]
  #
  # Set the bind address to a specific IP (IPv4 or IPv6):
  #
  host =  "_site_"
  # bind_host =
  # publish_host =
  [network.breaker]
  inflight_requests-limit = "100%"
  inflight_requests-overhead = 1

	[network.tcp]
 	no_delay = true
	keep_alive = true
	reuse_address = true
	# send_buffer_size =
	# receive_buffer_size =

[http]
  # Set a custom port for HTTP:
  #
  enabled = true
  port = 9200
  # publish_port =
  # bind_host =
  # publish_host =
  # host =
  max_content_length = "100mb"
  max_initial_line_length = "4kb"
  max_header_size = "8kB"
  compression = false
  compression_level = 6
  detailed_errors-enabled = true
  pipelining = true
  max_events = 10000
  [http.cors]
  enabled = false
  allow-origin = ""
  max-age = 1728000
  allow-methods = "OPTIONS, HEAD, GET, POST, PUT, DELETE"
  allow-headers = "X-Requested-With, Content-Type, Content-Length"
  allow-credentials = false



  # For more information, see the documentation at:
  # <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-network.html>

[transport]
# host =
# bind_host =
# publish_host =
# ping_schedule =

[transport.tcp]
port = "9300-9400"
# connect_timeout = "30s"
# compress = false

#[transport.profiles]
#[transport.profiles.default]
#port = "9300-9400"
#bind_host = "10.0.0.1"


#
# --------------------------------- Discovery ----------------------------------
#
[discovery]
  # Pass an initial list of hosts to perform discovery when new node is started:
  # The default list of hosts is ["127.0.0.1", "[::1]"]
  #
  ping_multicast_enabled = "false"
  #
  # Prevent the "split brain" by configuring the majority of nodes (total number of nodes / 2 + 1):
  #
  minimum_master_nodes = 1
  #
  # For more information, see the documentation at:
  # <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html>
  #
  [discovery.zen]
    ping_timeout = "3s"
    join_timeout = "60s"
    publish_timeout = "30s"
    no_master_block = "write"
  [discovery.zen.fd]
    ping_timeout = "30s"
    ping_interval = "1s"
    ping_retries = 3

  [discovery.zen.master_election]
    filter_client = true
    filter_data = false


#
# ---------------------------------- Gateway -----------------------------------
#
[gateway]
  #
  # Block initial recovery after a full cluster restart until N nodes are started:
  #
  recover_after_nodes   = ""
  #recover_after_master_nodes = ""
  #recover_after_data_nodes = ""

  #
  # The number of (data or master) nodes that are expected to be in the cluster.
  # Recovery of local shards will start as soon as the expected number of nodes
  # have joined the cluster. Defaults to 0
  #
  expected_nodes        = "0"
  #
  # The number of master nodes that are expected to be in the cluster. Recovery
  # of local shards will start as soon as the expected number of master nodes
  # have joined the cluster. Defaults to 0
  #
  expected_master_nodes = "0"
  #
  # The number of data nodes that are expected to be in the cluster. Recovery of
  # local shards will start as soon as the expected number of data nodes have
  # joined the cluster. Defaults to 0
  #
  expected_data_nodes   = "0"
  #
  # If the expected number of nodes is not achieved, the recovery process waits
  # for the configured amount of time before trying to recover regardless.
  # Defaults to 5m if one of the expected_nodes settings is configured.
  #
  recover_after_time    = ""
  #
  # For more information, see the documentation at:
  # <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-gateway.html>
  #

#
# ---------------------------------- Various -----------------------------------
#
[action]
  #
  # Require explicit names when deleting indices:
  #
  destructive_requires_name  = "true"

# ======================== Elasticsearch Logger Configuration =========================
[logger]
  level = "INFO"

# ======================== Elasticsearch Index Module Configuration =========================
[index]
  number_of_replicas = 1
  number_of_shards = 5

# ======================== Elasticsearch Plugins Configuration =========================
[plugins]
  cloud_aws_signer = ""

# ======================== Runtime Configuration =========================
[runtime]
  max_open_files = ""
  max_locked_memory = ""
  es_startup_sleep_time = ""
  es_java_opts = ""
  heapsize = ""
